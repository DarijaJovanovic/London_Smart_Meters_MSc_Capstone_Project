{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make sure only relevant acorns are in the data\n",
    "2. Make a boxplot \n",
    "3. Use the data without anomalies and calculate the average energy per day\n",
    "4. Merge this with the anomalies data and make a new column for average energy per day without the anomalies\n",
    "5. Save anomalies in excel file\n",
    "6. Do an if-else statement in excel to get over or under consumption\n",
    "7. split file into 3 part (go as far a here)\n",
    "-save a csv file with the over and under consumption anomalies\n",
    "-save a csv file with only over consumption anomalies\n",
    "-save a csv file with only under consumption anomalies\n",
    "8. Do visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting visualisation size\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affluent Achievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import combined file\n",
    "# importing daily dataset files\n",
    "block_0 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_0.csv\")\n",
    "block_1 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_1.csv\")\n",
    "block_2 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_2.csv\")\n",
    "block_3 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_3.csv\")\n",
    "block_4 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_4.csv\")\n",
    "block_5 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_5.csv\")\n",
    "block_6 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_6.csv\")\n",
    "block_7 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_7.csv\")\n",
    "household_acorn_info = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\informations_households_Cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking number of rows in first file\n",
    "len(block_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding all files in one data frame\n",
    "Dfs = [block_0, block_1, block_2, block_3, block_4, block_5, block_6,block_7]\n",
    "Combined = pd.concat(Dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking number of rows in combined dataframe\n",
    "len(Combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the combined dataframe\n",
    "Combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns\n",
    "Combined.rename(columns = {\"day\" : \"date\"}, inplace = True)\n",
    "household_acorn_info.rename(columns = {\"day\" : \"date\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging combined dataframe with household acorn details to see which acorn each household_id is associated with\n",
    "Combined =  Combined.merge(household_acorn_info,on='Household_Id').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if only acorns that belong to Affluent Achievers are in the dataframe \n",
    "Combined.Acorn.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Households belonging to acorn D were included so we removed them as they don't belong to Affluent Achievers\n",
    "Combined=Combined.loc[Combined['Acorn']!='ACORN-D']\n",
    "Combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if only acorns A,B and C remain in the dataframe\n",
    "Combined.Acorn.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot with outliers for Affluent Achivers\n",
    "Energy_Sum_BP= sns.boxplot(x= Combined[\"energy_sum\"])\n",
    "Energy_Sum_BP.set_xlim(0,500)\n",
    "plt.title(\"Affluent Achievers Sum Energy Boxplot\")\n",
    "plt.xlabel(\"Total Kilowatts Per Day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding energy_sum to 2 decimal places\n",
    "Combined.energy_sum = Combined.energy_sum.round(2)\n",
    "Combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewness and kurtosis values of energy sum column\n",
    "print (\"Skew: %f\"%Combined[\"energy_sum\"].skew())\n",
    "print (\"Kurt: %f\"%Combined[\"energy_sum\"].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many null values are in the energy_sum column\n",
    "Combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy sum is our target value for anomaly detection and it only had one empty value so we removed it\n",
    "# we decided not to replace it with the mean as energy sum is our target variable for anomlay detection\n",
    "# we did not think it was approprate to replace it with he mean because that household might have actually been an anomaly\n",
    "# as it was only one value that was empty, we decided to remove it\n",
    "Combined = Combined[Combined['energy_sum'].notna()]\n",
    "len(Combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the null value in the energy sum column was removed\n",
    "Combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the Isolation Forest algorithm on the energy_sum column\n",
    "aa_ad=IsolationForest(n_estimators=60, max_samples='auto', contamination=float(0.1),max_features=1.0)\n",
    "aa_ad.fit(Combined[['energy_sum']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding score and anomaly columns to the dataframe\n",
    "# if the anomaly column has a 1 that means the row is not an anomaly \n",
    "# if the anomaly column has a -1 that means the row is an anomaly\n",
    "Combined['Score']=aa_ad.decision_function(Combined[['energy_sum']])\n",
    "Combined['Anomaly']=aa_ad.predict(Combined[['energy_sum']])\n",
    "Combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the anomalies in a new dataframe\n",
    "anomalies=Combined.loc[Combined['Anomaly']==-1].reset_index()\n",
    "anomalies =anomalies.drop(['index'],axis=1)\n",
    "anomalies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many rows were anomalies\n",
    "len(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the new dataframe in descending order\n",
    "anomalies.sort_values(by=[\"energy_sum\"], ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of data that are anomalies\n",
    "print(\"Percentage of data that are anomalies:\",round(len(anomalies)/len(Combined)*100,1),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\AA_anomalies.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the data that are not anomalies in a new dataframe\n",
    "anomalies_removed_data=Combined.loc[Combined['Anomaly']!=-1].reset_index()\n",
    "anomalies_removed_data =anomalies_removed_data.drop(['index'],axis=1)\n",
    "anomalies_removed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many rows were not anomalies\n",
    "len(anomalies_removed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot without anomalies\n",
    "Energy_Sum_BP_RD= sns.boxplot(x= anomalies_removed_data[\"energy_sum\"])\n",
    "Energy_Sum_BP_RD.set_xlim(0,100)\n",
    "plt.title(\"Affluent Achievers Sum Energy Boxplot With Anomalies Removed\")\n",
    "plt.xlabel(\"Total Kilowatts Per Day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the average kilowatts per day\n",
    "# grouping by date and getting the average energy consumption for that day\n",
    "# this data will be merged with the anomaly data so that the anomaly consumption can be compared with the average consumption\n",
    "Average_Kilowatts_PerDay = anomalies_removed_data.groupby('date')['energy_sum'].mean()\n",
    "Average_Kilowatts_PerDay = pd.DataFrame(Average_Kilowatts_PerDay)\n",
    "Average_Kilowatts_PerDay.rename(columns={'energy_sum':'Average_Energy_That_Day'}, inplace= True)\n",
    "Average_Kilowatts_PerDay.Average_Energy_That_Day = Average_Kilowatts_PerDay.Average_Energy_That_Day.round(2)\n",
    "Average_Kilowatts_PerDay.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Average_Kilowatts_PerDay.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\Average_energy_per_day.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the average energy per day dataframe has 365 rows (1 year)\n",
    "len(Average_Kilowatts_PerDay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging anomalies data with average energy per day data\n",
    "# this was done so that we could compare the actual amount of energy the household used compared to average for each day\n",
    "# when this data was exported in excel, it helped us determine if the anomaly was an over or under consumption anomaly\n",
    "anomalies = anomalies.merge(Average_Kilowatts_PerDay, on = 'date').reset_index()\n",
    "anomalies=anomalies.drop(columns=['level_0'], axis = 1)\n",
    "anomalies=anomalies.drop(columns=['index'], axis = 1)\n",
    "anomalies.sort_values(by=[\"energy_sum\"], ascending=False).reset_index()\n",
    "anomalies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting data in descending order\n",
    "anomalies =anomalies.sort_values(by=[\"energy_sum\"], ascending=False).reset_index()\n",
    "anomalies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of anomalies\n",
    "len(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\AA_anomalies.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Months\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_anomalies = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\AA_anomalies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(AA_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by month and household_id\n",
    "# this helped us get the number of days per month each household's electricity readings were an anomaly\n",
    "# then we ordered the data in descending order\n",
    "grouped = (AA_anomalies.groupby(\n",
    "   ['month', 'Household_Id']\n",
    ").agg(\n",
    "    {\n",
    "         'date': 'count'\n",
    "    }\n",
    ")).sort_values(by=\"date\", ascending = False).reset_index()\n",
    "grouped= grouped.rename(columns={'date':'days'})\n",
    "print(grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the combined data frame in folder\n",
    "grouped.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\AA_anomalies_months.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rising Prosperity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_7 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_7.csv\")\n",
    "block_8 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_8.csv\")\n",
    "block_9 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_9.csv\")\n",
    "block_10 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_10.csv\")\n",
    "block_11 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_11.csv\")\n",
    "block_12 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_12.csv\")\n",
    "block_13 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_13.csv\")\n",
    "block_14 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_14.csv\")\n",
    "block_15 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_15.csv\")\n",
    "block_16 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_16.csv\")\n",
    "block_17 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_17.csv\")\n",
    "block_18 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_18.csv\")\n",
    "block_19 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_19.csv\")\n",
    "block_20 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_20.csv\")\n",
    "block_21 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_21.csv\")\n",
    "block_22 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_22.csv\")\n",
    "block_23 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_23.csv\")\n",
    "block_24 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_24.csv\")\n",
    "block_25 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_25.csv\")\n",
    "block_26 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_26.csv\")\n",
    "block_27 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_27.csv\")\n",
    "block_28 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_28.csv\")\n",
    "block_29 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_29.csv\")\n",
    "block_30 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_30.csv\")\n",
    "block_31 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_31.csv\")\n",
    "block_32 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_32.csv\")\n",
    "block_33 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_33.csv\")\n",
    "block_34 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_34.csv\")\n",
    "block_35 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_35.csv\")\n",
    "block_36 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_36.csv\")\n",
    "block_37 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_37.csv\")\n",
    "block_38 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_38.csv\")\n",
    "block_39 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_39.csv\")\n",
    "block_40 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_40.csv\")\n",
    "block_41 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_41.csv\")\n",
    "block_42 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_42.csv\")\n",
    "block_43 = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\block_43.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding all files in one data frame\n",
    "Dfs = [block_7,block_8,block_9,block_10,block_11,block_12,block_13,block_14,block_15,block_16,block_17,block_18,block_19,block_20,block_21,block_22,block_23,block_24,block_25,block_26,block_27,block_28,block_29,block_30,block_31,block_32,block_33,block_34,block_35,block_36,block_37,block_38,block_39,block_40,block_41,block_42,block_43]\n",
    "Combined = pd.concat(Dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of rows in each dataframe\n",
    "# make sure that the number of rows makes sense\n",
    "len(Combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that the combined data frame \n",
    "Combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns\n",
    "Combined.rename(columns = {\"day\" : \"date\"}, inplace = True)\n",
    "household_acorn_info.rename(columns = {\"day\" : \"date\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging combined energy readings with household acorn details\n",
    "Combined =  Combined.merge(household_acorn_info,on='Household_Id').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if only acorns that belong to Affluent Achievers are in the dataframe \n",
    "# I saw that households belonging to acorn D were included so I removed them\n",
    "Combined.Acorn.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined=Combined.loc[Combined['Acorn']!='ACORN-F']\n",
    "Combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the correct acorn groups of Affluent Achievers remain\n",
    "Combined.Acorn.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot with outliers \n",
    "Energy_Sum_BP= sns.boxplot(x= Combined[\"energy_sum\"])\n",
    "Energy_Sum_BP.set_xlim(0,500)\n",
    "plt.title(\"Sum Energy Boxplot\")\n",
    "plt.xlabel(\"Total Kilowatts Per Day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding energy_sum to 2 decimal places\n",
    "Combined.energy_sum = Combined.energy_sum.round(2)\n",
    "Combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewness and kurtosis values of energy sum column\n",
    "print (\"Skew: %f\"%Combined[\"energy_sum\"].skew())\n",
    "print (\"Kurt: %f\"%Combined[\"energy_sum\"].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing inf values with nan\n",
    "Combined.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many null values are in the energy_sum column\n",
    "count_nan = len(Combined) - Combined.count()\n",
    "print(count_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping energy_sum rows that are not empty\n",
    "Combined = Combined[Combined['energy_sum'].notna()]\n",
    "len(Combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing if null values in energy_sum column were removed\n",
    "count_nan = len(Combined) - Combined.count()\n",
    "print(count_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the isolation tree model on the energy_sum column\n",
    "rp_ad=IsolationForest(n_estimators=60, max_samples='auto', contamination=float(0.1),max_features=1.0)\n",
    "rp_ad.fit(Combined[['energy_sum']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding score and anomaly columns to the dataframe\n",
    "# if the anomaly column has a 1 that means the row is not an anomaly, if it's a -1 that means it's an anomaly\n",
    "Combined['Score']=rp_ad.decision_function(Combined[['energy_sum']])\n",
    "Combined['Anomaly']=rp_ad.predict(Combined[['energy_sum']])\n",
    "Combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the anomalies in a new dataframe\n",
    "anomalies=Combined.loc[Combined['Anomaly']==-1].reset_index()\n",
    "anomalies =anomalies.drop(['index'],axis=1)\n",
    "anomalies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting the new dataframe in descending order\n",
    "anomalies.sort_values(by=[\"energy_sum\"], ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of data that are anomalies\n",
    "print(\"Percentage of data that are anomalies:\",round(len(anomalies)/len(Combined)*100,1),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\RP_anomalies.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the data that are not anomalies in a new dataframe\n",
    "anomalies_removed_data=Combined.loc[Combined['Anomaly']!=-1].reset_index()\n",
    "anomalies_removed_data =anomalies_removed_data.drop(['index'],axis=1)\n",
    "anomalies_removed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(anomalies_removed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot without anomalies\n",
    "Energy_Sum_BP_RD= sns.boxplot(x= anomalies_removed_data[\"energy_sum\"])\n",
    "Energy_Sum_BP_RD.set_xlim(0,100)\n",
    "plt.title(\"Sum Energy Boxplot With Anomalies Removed\")\n",
    "plt.xlabel(\"Total Kilowatts Per Day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the average kilowatts per day\n",
    "# grouping by day and getting the average energy consumption for that day\n",
    "# this data will be merged with the anomaly data\n",
    "Average_Kilowatts_PerDay = anomalies_removed_data.groupby('date')['energy_sum'].mean()\n",
    "Average_Kilowatts_PerDay = pd.DataFrame(Average_Kilowatts_PerDay)\n",
    "Average_Kilowatts_PerDay.rename(columns={'energy_sum':'Average_Energy_That_Day'}, inplace= True)\n",
    "Average_Kilowatts_PerDay.Average_Energy_That_Day = Average_Kilowatts_PerDay.Average_Energy_That_Day.round(2)\n",
    "Average_Kilowatts_PerDay.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging anomalies data with average energy per day data\n",
    "# this was done so that we could compare the actual amount of energy the household used compared to average for each day\n",
    "# when this data was exported in excel, it helped us determine if the anomaly was an over or under consumption anomaly\n",
    "anomalies = anomalies.merge(Average_Kilowatts_PerDay, on = 'date').reset_index()\n",
    "anomalies=anomalies.drop(columns=['level_0'], axis = 1)\n",
    "anomalies=anomalies.drop(columns=['index'], axis = 1)\n",
    "anomalies.sort_values(by=[\"energy_sum\"], ascending=False).reset_index()\n",
    "anomalies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting data in descending order\n",
    "anomalies =anomalies.sort_values(by=[\"energy_sum\"], ascending=False).reset_index()\n",
    "anomalies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\RP_anomalies.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RP_anomalies = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\RP_anomalies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unnecessary column\n",
    "RP_anomalies=RP_anomalies.drop(['index'], axis=1)\n",
    "RP_anomalies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RP_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by month and household \n",
    "# this helped us get the number of days per month each household's electricity readings were an anomaly\n",
    "# then we ordered the data in descending order\n",
    "grouped = (RP_anomalies.groupby(\n",
    "   ['month', 'Household_Id']\n",
    ").agg(\n",
    "    {\n",
    "         'date': 'count'\n",
    "    }\n",
    ")).sort_values(by=\"date\", ascending = False).reset_index()\n",
    "grouped= grouped.rename(columns={'date':'days'})\n",
    "print(grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the combined data frame in folder\n",
    "grouped.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\RP_anomalies_months.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Community Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_Over = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\AA_Over.csv\")\n",
    "AA_Under = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\AA_Under.csv\")\n",
    "RP_Over = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\RP_Over.csv\")\n",
    "RP_Under = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\RP_Under.csv\")\n",
    "CC_Over = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\CC_anomalies_Over.csv\")\n",
    "CC_Under = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\CC_anomalies_Under.csv\")\n",
    "FS_Over = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\FS_anomalies_over_count.csv\")\n",
    "FS_Under = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\FS_anomalies_under_count.csv\")\n",
    "UA_Over = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\UA_anomalies_OVER.csv\")\n",
    "UA_Under = pd.read_csv(r\"C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\UA_anomalies_Under.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(AA_Over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by month and household \n",
    "# this helped us get the number of days per month each household's electricity readings were an anomaly\n",
    "# then we ordered the data in descending order\n",
    "AA_g = (AA_Over.groupby(\n",
    "   ['month', 'Household_Id']\n",
    ").agg(\n",
    "    {\n",
    "         'date': 'count'\n",
    "    }\n",
    ")).sort_values(by=\"date\", ascending = False).reset_index()\n",
    "AA_g= AA_g.rename(columns={'date':'days'})\n",
    "print(AA_g.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the combined data frame in folder\n",
    "AA_g.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\AA_Over_months.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(AA_Under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by month and household \n",
    "# this helped us get the number of days per month each household's electricity readings were an anomaly\n",
    "# then we ordered the data in descending order\n",
    "AA_g1 = (AA_Under.groupby(\n",
    "   ['month', 'Household_Id']\n",
    ").agg(\n",
    "    {\n",
    "         'date': 'count'\n",
    "    }\n",
    ")).sort_values(by=\"date\", ascending = False).reset_index()\n",
    "AA_g1= AA_g1.rename(columns={'date':'days'})\n",
    "print(AA_g1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the combined data frame in folder\n",
    "AA_g1.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\AA_Under_months.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RP_Over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by month and household \n",
    "# this helped us get the number of days per month each household's electricity readings were an anomaly\n",
    "# then we ordered the data in descending order\n",
    "RP_g = (RP_Over.groupby(\n",
    "   ['month', 'Household_Id']\n",
    ").agg(\n",
    "    {\n",
    "         'date': 'count'\n",
    "    }\n",
    ")).sort_values(by=\"date\", ascending = False).reset_index()\n",
    "RP_g= RP_g.rename(columns={'date':'days'})\n",
    "print(RP_g.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the combined data frame in folder\n",
    "RP_g.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\RP_Over_months.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RP_Under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by month and household \n",
    "# this helped us get the number of days per month each household's electricity readings were an anomaly\n",
    "# then we ordered the data in descending order\n",
    "RP_g1 = (RP_Under.groupby(\n",
    "   ['month', 'Household_Id']\n",
    ").agg(\n",
    "    {\n",
    "         'date': 'count'\n",
    "    }\n",
    ")).sort_values(by=\"date\", ascending = False).reset_index()\n",
    "RP_g1= RP_g1.rename(columns={'date':'days'})\n",
    "print(RP_g1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the combined data frame in folder\n",
    "RP_g1.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\RP_Under_months.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CC_Over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by month and household \n",
    "# this helped us get the number of days per month each household's electricity readings were an anomaly\n",
    "# then we ordered the data in descending order\n",
    "CC_g = (CC_Over.groupby(\n",
    "   ['month', 'Household_Id']\n",
    ").agg(\n",
    "    {\n",
    "         'date': 'count'\n",
    "    }\n",
    ")).sort_values(by=\"date\", ascending = False).reset_index()\n",
    "CC_g= CC_g.rename(columns={'date':'days'})\n",
    "print(CC_g.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the combined data frame in folder\n",
    "CC_g.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\CC_Over_months.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CC_Under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by month and household \n",
    "# this helped us get the number of days per month each household's electricity readings were an anomaly\n",
    "# then we ordered the data in descending order\n",
    "CC_g1 = (CC_Under.groupby(\n",
    "   ['month', 'Household_Id']\n",
    ").agg(\n",
    "    {\n",
    "         'date': 'count'\n",
    "    }\n",
    ")).sort_values(by=\"date\", ascending = False).reset_index()\n",
    "CC_g1= CC_g1.rename(columns={'date':'days'})\n",
    "print(CC_g1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the combined data frame in folder\n",
    "CC_g1.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\CC_Under_months.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FS_Over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by month and household \n",
    "# this helped us get the number of days per month each household's electricity readings were an anomaly\n",
    "# then we ordered the data in descending order\n",
    "FS_g = (FS_Over.groupby(\n",
    "   ['month', 'Household_Id']\n",
    ").agg(\n",
    "    {\n",
    "         'date': 'count'\n",
    "    }\n",
    ")).sort_values(by=\"date\", ascending = False).reset_index()\n",
    "FS_g= FS_g.rename(columns={'date':'days'})\n",
    "print(FS_g.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the combined data frame in folder\n",
    "FS_g.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\FS_Over_months.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FS_Under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by month and household \n",
    "# this helped us get the number of days per month each household's electricity readings were an anomaly\n",
    "# then we ordered the data in descending order\n",
    "FS_g1 = (FS_Under.groupby(\n",
    "   ['month', 'Household_Id']\n",
    ").agg(\n",
    "    {\n",
    "         'date': 'count'\n",
    "    }\n",
    ")).sort_values(by=\"date\", ascending = False).reset_index()\n",
    "FS_g1= FS_g1.rename(columns={'date':'days'})\n",
    "print(FS_g1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the combined data frame in folder\n",
    "FS_g1.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\FS_Under_months.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(UA_Over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by month and household \n",
    "# this helped us get the number of days per month each household's electricity readings were an anomaly\n",
    "# then we ordered the data in descending order\n",
    "UA_g = (UA_Over.groupby(\n",
    "   ['month', 'Household_Id']\n",
    ").agg(\n",
    "    {\n",
    "         'date': 'count'\n",
    "    }\n",
    ")).sort_values(by=\"date\", ascending = False).reset_index()\n",
    "UA_g= UA_g.rename(columns={'date':'days'})\n",
    "print(UA_g.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the combined data frame in folder\n",
    "UA_g.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\UA_Over_months.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(UA_Under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by month and household \n",
    "# this helped us get the number of days per month each household's electricity readings were an anomaly\n",
    "# then we ordered the data in descending order\n",
    "UA_g1 = (UA_Under.groupby(\n",
    "   ['month', 'Household_Id']\n",
    ").agg(\n",
    "    {\n",
    "         'date': 'count'\n",
    "    }\n",
    ")).sort_values(by=\"date\", ascending = False).reset_index()\n",
    "UA_g1= UA_g1.rename(columns={'date':'days'})\n",
    "print(UA_g1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the combined data frame in folder\n",
    "UA_g1.to_csv(r'C:\\Users\\m\\Desktop\\Masters Modules\\MS5103 Business Analytics Project\\Datasets\\Smart Meters\\Cleaned Data\\daily_dataset\\UA_Under_months.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
